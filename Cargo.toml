[package]
name = "laurus-llm-rust"
version = "0.1.0"
edition = "2021"
authors = ["LunarLaurus"]
description = "Rust LLM server using Axum + llama.cpp"

[dependencies]
# Web server
axum = { version = "0.6", features = ["ws", "headers"] }
hyper = "0.14"
tower = "0.4"

# Async runtime
tokio = { version = "1", features = ["full"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["fmt", "env-filter"] }

# Concurrency & utilities
parking_lot = "0.12"
anyhow = "1.0"
async-stream = "0.3"
futures = "0.3"

# LLaMA CPP bindings
llama-cpp-2 = { version = "0.1.122", features = ["cuda"] }

# Optional for SSE streaming
tokio-stream = "0.1"
